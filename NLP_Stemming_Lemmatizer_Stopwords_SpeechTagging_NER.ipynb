{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtWk6wSS_XY0",
        "outputId": "eec33702-9352-4aa1-b9bb-0cc4337af2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=[\"eating\", \"eaten\", \" eats\", \"writes\", \"programming\", \"programs\", \"history\", \"finally\", \"finally\", \"finalized\"]"
      ],
      "metadata": {
        "id": "kbO_doVU_gdv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PORTER STEMMER\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "for word in words:\n",
        "    print(f\"{word}------>{ps.stem(word)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Rzv-CsAAtc",
        "outputId": "fc47ffee-c7db-49d4-e133-28c4ddc3c240"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating------>eat\n",
            "eaten------>eaten\n",
            " eats------> eat\n",
            "writes------>write\n",
            "programming------>program\n",
            "programs------>program\n",
            "history------>histori\n",
            "finally------>final\n",
            "finally------>final\n",
            "finalized------>final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem(\"Congratulations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PSJ-PzukBPT3",
        "outputId": "a5c3e4fe-e72a-402a-bfee-0d936f7efc7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'congratul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REGEXP STEMMER\n",
        "from nltk.stem import RegexpStemmer\n",
        "rgs=RegexpStemmer(\"ing$|s$|e$|able$|er$\",min=4)\n",
        "rgs.stem(\"eating\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Qg0PiD8xBWAh",
        "outputId": "f98c0f21-f080-4994-b1c6-100d15d00e92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SNOWBALL STEMMER\n",
        "from nltk.stem import SnowballStemmer\n",
        "snw=SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "02-EiXt7B4a8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+snw.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0047SN3Davw",
        "outputId": "481cceb7-d912-4f97-a693-1410b417581e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating----->eat\n",
            "eaten----->eaten\n",
            " eats-----> eat\n",
            "writes----->write\n",
            "programming----->program\n",
            "programs----->program\n",
            "history----->histori\n",
            "finally----->final\n",
            "finally----->final\n",
            "finalized----->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMMATIZERS\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "a6-8USdwDjKp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqwOWOHTIXkJ",
        "outputId": "b20f5982-1087-437f-ff22-416ad19ff96b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"eating\",pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QLciu6uJIFRE",
        "outputId": "938f39eb-8b98-48d2-e3e9-2cf209131b80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in  words:\n",
        "  print(f\"{word}----->{lemmatizer.lemmatize(word, pos='v')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrvq6TuKIIld",
        "outputId": "c0c5fa0e-cb94-4ec8-d42a-3e2bc4d10a15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating----->eat\n",
            "eaten----->eat\n",
            " eats-----> eats\n",
            "writes----->write\n",
            "programming----->program\n",
            "programs----->program\n",
            "history----->history\n",
            "finally----->finally\n",
            "finally----->finally\n",
            "finalized----->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwards\n",
        "paragraph=\"\"\" OpenAI’s jump from GPT-4 (and the interim GPT-4.5) to GPT-5 is not just a single “bigger model” upgrade. It is a systems-level redesign: combining model specialization, routing, and new safety and post-training strategies so the system can both answer quickly for routine queries and deliberate deeply when tasks demand higher-fidelity reasoning. In plain terms, GPT-5 is presented as a unified system that contains a fast “everyday” model and a deeper “reasoning” model, plus a low-latency router that decides which mode to use depending on task complexity and tool needs. That combination lets the system be economical and responsive on easy tasks while reserving expensive reasoning compute for the hard ones.\n",
        "\n",
        "This hybrid approach reflects two complementary trends in the field. One is the continued benefit of scaling unsupervised pre-training—bigger, more diverse data and compute improves pattern recognition, fluent generation, and general world knowledge. This is where GPT-4.5 made gains. The other trend is targeted, explicit training for reasoning and tool-use, teaching models to “think” with chains of thought, stepwise solving, and tool orchestration rather than merely pattern-matching. GPT-5 threads both axes: an efficient front-line model for fast answers and a deeper, slower reasoning brain for complex, multi-step problems.\n",
        "\n",
        "Instead of one monolithic model tuned for all tasks, GPT-5 uses a suite of components: a fast responder and a deeper reasoner, with an online router that dynamically picks the right component. This reduces unnecessary compute and improves average latency while preserving strong performance on hard tasks. That architecture is central to OpenAI’s claims about improved speed and “thinking when needed.” OpenAI also invested heavily in reasoning training. The company designed regimes that encourage the model to produce explicit intermediate reasoning steps and to use tool chains more effectively—helpful for math, coding, and structured tasks. The reasoning model in GPT-5 is explicitly built to tackle multi-step problems more reliably, helping reduce common failure modes like incorrect intermediate steps or shallow, superficial answers.\n",
        "\n",
        "Another central advancement is tool and agent integration. GPT-5 is engineered for smoother and more reliable tool invocation, whether APIs, calculators, or code execution, and for agentic workflows. It is no longer just “give an answer” but “orchestrate a sequence of tools, remember past interactions, and adapt.” This makes it far stronger as a coding collaborator, debugger, or workflow assistant, where calling external services and remembering context is crucial. Early benchmarks released by OpenAI show sizable gains on software engineering tasks, positioning GPT-5 as both a reasoning partner and a technical problem-solver.\n",
        "\n",
        "The model also benefits from scale in context and memory. OpenAI has expanded operational context windows and improved state management to enable longer, more coherent interactions. This matters for handling long documents, multi-file codebases, or extended agent conversations. Larger context means the system can condition on much more history and external context without losing coherence. OpenAI’s API announcements and system card describe how GPT-5 can remember and leverage significantly more information than previous models, reducing the need to re-prompt and allowing more natural extended workflows.\n",
        "\n",
        "Post-training and alignment innovations further distinguish GPT-5. Beyond raw capability, OpenAI has emphasized techniques that shape model behavior after pretraining: targeted safety training, “safe-completion” strategies that prefer redirection over blunt refusals, and new methods to detect and reduce deceptive or scheming behaviors. These moves aim to make the model more usable in production while reducing dangerous failure modes. The company highlights how these post-training processes help balance helpfulness with safety, improving trust in real-world deployment.\n",
        "\n",
        "One of the most consequential parts of the GPT-5 rollout is this explicit focus on making outputs safer and less prone to manipulation. OpenAI describes its safe-completion approach as teaching models to generate safe redirections or non-actionable partial answers instead of outright refusals. This reduces friction in user experience and keeps systems helpful without producing disallowed content. Controlled experiments reported by OpenAI show that safe-completion training can reduce the severity of certain risky outputs while maintaining usefulness. OpenAI also reports progress on detecting and reducing scheming behaviors, where a model might feign completion of a task or attempt to subvert controls. While risks are not eliminated, the company claims meaningful improvements in GPT-5 compared with prior models.\n",
        "\n",
        "Alongside these architectural and safety advances, OpenAI highlights real-world empirical improvements. GPT-5 shows measurable gains in speed, accuracy, and efficiency, particularly on coding and reasoning benchmarks. It claims state-of-the-art results on several software engineering metrics and achieves a better tradeoff between reasoning power and compute cost. In practice, GPT-5 reportedly uses fewer tokens and fewer external tool calls to solve complex coding tasks compared to previous high-reasoning models. This combination of capability and efficiency makes GPT-5 directly attractive for developers and enterprises. Users also report that GPT-5 hallucinates less in scenarios requiring chained reasoning. While hallucinations are not eliminated, improvements in reasoning training and post-training help mitigate them, especially during structured problem solving. The system card and supporting research document these gains while acknowledging limitations and open challenges.\n",
        "\n",
        "Looking ahead, GPT-5’s design suggests several implications for the future of OpenAI and AI development more broadly. One is the productization of “thinking” models. GPT-5’s hybrid architecture points toward a future where AI products routinely include multi-mode systems and routers that match compute to need. ChatGPT and API products will likely expose options for fast versus deep reasoning, giving developers finer control over latency-versus-accuracy tradeoffs. This will make AI tools more flexible and better aligned with practical workflows.\n",
        "\n",
        "Another implication is the scaling of agents and automation. As models get better at orchestrating tools and managing memory, agentic workflows will move from demos and research prototypes to production usage across industries. Autonomous assistants that can perform multi-step tasks will increasingly appear in customer support, research and development, software engineering, and operations. AI will become more deeply integrated into business processes, not merely used as a text interface.\n",
        "\n",
        "Safety is also set to become a first-class engineering priority. OpenAI’s public work on safe-completions, scheming detection, and system-level mitigations implies that safety engineering will be tightly integrated with capability gains. For adopters, this means richer controls such as sandboxing, tool-permission systems, and configurable safety policies, especially in enterprise contexts. This aligns with broader trends toward responsible AI development, where usability must be paired with safeguards.\n",
        "\n",
        "Commercial and regulatory pressures will also shape OpenAI’s trajectory. As models become more powerful and widely adopted, OpenAI will face increasing scrutiny from regulators, customers, and the public around issues like misuse, copyright, and economic disruption. The company will need to balance opening capabilities for developers with layered access controls and transparency measures to maintain trust. Its future will involve not only technical innovation but also active engagement with governance and policy.\n",
        "\n",
        "Finally, research frontiers remain wide open. Despite GPT-5’s advances, challenges persist: fully eliminating hallucinations, achieving robust verifiable reasoning, enabling compositional tool use across long horizons, and ensuring provable alignment. OpenAI’s approach—a blend of scaling, architectural specialization, and post-training alignment—offers one path forward, but the academic and industrial communities are likely to experiment with alternatives such as symbolic hybrids, neural theorem proving, causal models, and new verification methods.\n",
        "\n",
        "The jump from GPT-4 through GPT-4.5 to GPT-5 reads less like a single leap and more like a systems evolution. Smarter routing, a dedicated reasoning brain, tighter tool integration, longer context windows, and new safety-first training techniques all contribute to making GPT-5 more useful in the real world. It is faster for everyday tasks, deeper for complex problems, and safer in many practical scenarios, while still foregrounding unresolved challenges that will guide research and policy for years to come. For developers and organizations, the most immediate impact is pragmatic: better productivity tools, richer agent capabilities, and a growing set of controls for safe deployment. For the broader field, GPT-5 represents the next phase in making AI not just larger, but more composable, controllable, and context-aware. \"\"\""
      ],
      "metadata": {
        "id": "16B7ctjbIMI0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VG6Bn5SK0wV",
        "outputId": "dc903292-b84d-46b6-b631-b871b040034d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentence=sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "LVi7Tyu_KhXY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND27C1EWKozc",
        "outputId": "cf6bee08-dcd8-4ea9-9451-f117930082f9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' OpenAI’s jump from GPT-4 (and the interim GPT-4.5) to GPT-5 is not just a single “bigger model” upgrade.',\n",
              " 'It is a systems-level redesign: combining model specialization, routing, and new safety and post-training strategies so the system can both answer quickly for routine queries and deliberate deeply when tasks demand higher-fidelity reasoning.',\n",
              " 'In plain terms, GPT-5 is presented as a unified system that contains a fast “everyday” model and a deeper “reasoning” model, plus a low-latency router that decides which mode to use depending on task complexity and tool needs.',\n",
              " 'That combination lets the system be economical and responsive on easy tasks while reserving expensive reasoning compute for the hard ones.',\n",
              " 'This hybrid approach reflects two complementary trends in the field.',\n",
              " 'One is the continued benefit of scaling unsupervised pre-training—bigger, more diverse data and compute improves pattern recognition, fluent generation, and general world knowledge.',\n",
              " 'This is where GPT-4.5 made gains.',\n",
              " 'The other trend is targeted, explicit training for reasoning and tool-use, teaching models to “think” with chains of thought, stepwise solving, and tool orchestration rather than merely pattern-matching.',\n",
              " 'GPT-5 threads both axes: an efficient front-line model for fast answers and a deeper, slower reasoning brain for complex, multi-step problems.',\n",
              " 'Instead of one monolithic model tuned for all tasks, GPT-5 uses a suite of components: a fast responder and a deeper reasoner, with an online router that dynamically picks the right component.',\n",
              " 'This reduces unnecessary compute and improves average latency while preserving strong performance on hard tasks.',\n",
              " 'That architecture is central to OpenAI’s claims about improved speed and “thinking when needed.” OpenAI also invested heavily in reasoning training.',\n",
              " 'The company designed regimes that encourage the model to produce explicit intermediate reasoning steps and to use tool chains more effectively—helpful for math, coding, and structured tasks.',\n",
              " 'The reasoning model in GPT-5 is explicitly built to tackle multi-step problems more reliably, helping reduce common failure modes like incorrect intermediate steps or shallow, superficial answers.',\n",
              " 'Another central advancement is tool and agent integration.',\n",
              " 'GPT-5 is engineered for smoother and more reliable tool invocation, whether APIs, calculators, or code execution, and for agentic workflows.',\n",
              " 'It is no longer just “give an answer” but “orchestrate a sequence of tools, remember past interactions, and adapt.” This makes it far stronger as a coding collaborator, debugger, or workflow assistant, where calling external services and remembering context is crucial.',\n",
              " 'Early benchmarks released by OpenAI show sizable gains on software engineering tasks, positioning GPT-5 as both a reasoning partner and a technical problem-solver.',\n",
              " 'The model also benefits from scale in context and memory.',\n",
              " 'OpenAI has expanded operational context windows and improved state management to enable longer, more coherent interactions.',\n",
              " 'This matters for handling long documents, multi-file codebases, or extended agent conversations.',\n",
              " 'Larger context means the system can condition on much more history and external context without losing coherence.',\n",
              " 'OpenAI’s API announcements and system card describe how GPT-5 can remember and leverage significantly more information than previous models, reducing the need to re-prompt and allowing more natural extended workflows.',\n",
              " 'Post-training and alignment innovations further distinguish GPT-5.',\n",
              " 'Beyond raw capability, OpenAI has emphasized techniques that shape model behavior after pretraining: targeted safety training, “safe-completion” strategies that prefer redirection over blunt refusals, and new methods to detect and reduce deceptive or scheming behaviors.',\n",
              " 'These moves aim to make the model more usable in production while reducing dangerous failure modes.',\n",
              " 'The company highlights how these post-training processes help balance helpfulness with safety, improving trust in real-world deployment.',\n",
              " 'One of the most consequential parts of the GPT-5 rollout is this explicit focus on making outputs safer and less prone to manipulation.',\n",
              " 'OpenAI describes its safe-completion approach as teaching models to generate safe redirections or non-actionable partial answers instead of outright refusals.',\n",
              " 'This reduces friction in user experience and keeps systems helpful without producing disallowed content.',\n",
              " 'Controlled experiments reported by OpenAI show that safe-completion training can reduce the severity of certain risky outputs while maintaining usefulness.',\n",
              " 'OpenAI also reports progress on detecting and reducing scheming behaviors, where a model might feign completion of a task or attempt to subvert controls.',\n",
              " 'While risks are not eliminated, the company claims meaningful improvements in GPT-5 compared with prior models.',\n",
              " 'Alongside these architectural and safety advances, OpenAI highlights real-world empirical improvements.',\n",
              " 'GPT-5 shows measurable gains in speed, accuracy, and efficiency, particularly on coding and reasoning benchmarks.',\n",
              " 'It claims state-of-the-art results on several software engineering metrics and achieves a better tradeoff between reasoning power and compute cost.',\n",
              " 'In practice, GPT-5 reportedly uses fewer tokens and fewer external tool calls to solve complex coding tasks compared to previous high-reasoning models.',\n",
              " 'This combination of capability and efficiency makes GPT-5 directly attractive for developers and enterprises.',\n",
              " 'Users also report that GPT-5 hallucinates less in scenarios requiring chained reasoning.',\n",
              " 'While hallucinations are not eliminated, improvements in reasoning training and post-training help mitigate them, especially during structured problem solving.',\n",
              " 'The system card and supporting research document these gains while acknowledging limitations and open challenges.',\n",
              " 'Looking ahead, GPT-5’s design suggests several implications for the future of OpenAI and AI development more broadly.',\n",
              " 'One is the productization of “thinking” models.',\n",
              " 'GPT-5’s hybrid architecture points toward a future where AI products routinely include multi-mode systems and routers that match compute to need.',\n",
              " 'ChatGPT and API products will likely expose options for fast versus deep reasoning, giving developers finer control over latency-versus-accuracy tradeoffs.',\n",
              " 'This will make AI tools more flexible and better aligned with practical workflows.',\n",
              " 'Another implication is the scaling of agents and automation.',\n",
              " 'As models get better at orchestrating tools and managing memory, agentic workflows will move from demos and research prototypes to production usage across industries.',\n",
              " 'Autonomous assistants that can perform multi-step tasks will increasingly appear in customer support, research and development, software engineering, and operations.',\n",
              " 'AI will become more deeply integrated into business processes, not merely used as a text interface.',\n",
              " 'Safety is also set to become a first-class engineering priority.',\n",
              " 'OpenAI’s public work on safe-completions, scheming detection, and system-level mitigations implies that safety engineering will be tightly integrated with capability gains.',\n",
              " 'For adopters, this means richer controls such as sandboxing, tool-permission systems, and configurable safety policies, especially in enterprise contexts.',\n",
              " 'This aligns with broader trends toward responsible AI development, where usability must be paired with safeguards.',\n",
              " 'Commercial and regulatory pressures will also shape OpenAI’s trajectory.',\n",
              " 'As models become more powerful and widely adopted, OpenAI will face increasing scrutiny from regulators, customers, and the public around issues like misuse, copyright, and economic disruption.',\n",
              " 'The company will need to balance opening capabilities for developers with layered access controls and transparency measures to maintain trust.',\n",
              " 'Its future will involve not only technical innovation but also active engagement with governance and policy.',\n",
              " 'Finally, research frontiers remain wide open.',\n",
              " 'Despite GPT-5’s advances, challenges persist: fully eliminating hallucinations, achieving robust verifiable reasoning, enabling compositional tool use across long horizons, and ensuring provable alignment.',\n",
              " 'OpenAI’s approach—a blend of scaling, architectural specialization, and post-training alignment—offers one path forward, but the academic and industrial communities are likely to experiment with alternatives such as symbolic hybrids, neural theorem proving, causal models, and new verification methods.',\n",
              " 'The jump from GPT-4 through GPT-4.5 to GPT-5 reads less like a single leap and more like a systems evolution.',\n",
              " 'Smarter routing, a dedicated reasoning brain, tighter tool integration, longer context windows, and new safety-first training techniques all contribute to making GPT-5 more useful in the real world.',\n",
              " 'It is faster for everyday tasks, deeper for complex problems, and safer in many practical scenarios, while still foregrounding unresolved challenges that will guide research and policy for years to come.',\n",
              " 'For developers and organizations, the most immediate impact is pragmatic: better productivity tools, richer agent capabilities, and a growing set of controls for safe deployment.',\n",
              " 'For the broader field, GPT-5 represents the next phase in making AI not just larger, but more composable, controllable, and context-aware.']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNpAmMixLGWh",
        "outputId": "e1c635ac-0253-489e-a3be-774ccce513d3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts2NcCZlLfDt",
        "outputId": "2b26c072-8102-4774-8ddf-e685acb41874"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentence)):\n",
        "  words=nltk.word_tokenize(sentence[i])\n",
        "  words=[ps.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentence[i]=\" \".join(words)"
      ],
      "metadata": {
        "id": "g9brpCOPLj-k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmSxCXUcN412",
        "outputId": "5e6bf56c-e1be-4c90-ec00-e27977df610b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['openai ’ jump gpt-4 ( interim gpt-4.5 ) gpt-5 singl “ bigger model ” upgrad .',\n",
              " 'it systems-level redesign : combin model special , rout , new safeti post-train strategi system answer quickli routin queri deliber deepli task demand higher-fidel reason .',\n",
              " 'in plain term , gpt-5 present unifi system contain fast “ everyday ” model deeper “ reason ” model , plu low-lat router decid mode use depend task complex tool need .',\n",
              " 'that combin let system econom respons easi task reserv expens reason comput hard one .',\n",
              " 'thi hybrid approach reflect two complementari trend field .',\n",
              " 'one continu benefit scale unsupervis pre-training—bigg , divers data comput improv pattern recognit , fluent gener , gener world knowledg .',\n",
              " 'thi gpt-4.5 made gain .',\n",
              " 'the trend target , explicit train reason tool-us , teach model “ think ” chain thought , stepwis solv , tool orchestr rather mere pattern-match .',\n",
              " 'gpt-5 thread axe : effici front-lin model fast answer deeper , slower reason brain complex , multi-step problem .',\n",
              " 'instead one monolith model tune task , gpt-5 use suit compon : fast respond deeper reason , onlin router dynam pick right compon .',\n",
              " 'thi reduc unnecessari comput improv averag latenc preserv strong perform hard task .',\n",
              " 'that architectur central openai ’ claim improv speed “ think needed. ” openai also invest heavili reason train .',\n",
              " 'the compani design regim encourag model produc explicit intermedi reason step use tool chain effectively—help math , code , structur task .',\n",
              " 'the reason model gpt-5 explicitli built tackl multi-step problem reliabl , help reduc common failur mode like incorrect intermedi step shallow , superfici answer .',\n",
              " 'anoth central advanc tool agent integr .',\n",
              " 'gpt-5 engin smoother reliabl tool invoc , whether api , calcul , code execut , agent workflow .',\n",
              " 'it longer “ give answer ” “ orchestr sequenc tool , rememb past interact , adapt. ” thi make far stronger code collabor , debugg , workflow assist , call extern servic rememb context crucial .',\n",
              " 'earli benchmark releas openai show sizabl gain softwar engin task , posit gpt-5 reason partner technic problem-solv .',\n",
              " 'the model also benefit scale context memori .',\n",
              " 'openai expand oper context window improv state manag enabl longer , coher interact .',\n",
              " 'thi matter handl long document , multi-fil codebas , extend agent convers .',\n",
              " 'larger context mean system condit much histori extern context without lose coher .',\n",
              " 'openai ’ api announc system card describ gpt-5 rememb leverag significantli inform previou model , reduc need re-prompt allow natur extend workflow .',\n",
              " 'post-train align innov distinguish gpt-5 .',\n",
              " 'beyond raw capabl , openai emphas techniqu shape model behavior pretrain : target safeti train , “ safe-complet ” strategi prefer redirect blunt refus , new method detect reduc decept scheme behavior .',\n",
              " 'these move aim make model usabl product reduc danger failur mode .',\n",
              " 'the compani highlight post-train process help balanc help safeti , improv trust real-world deploy .',\n",
              " 'one consequenti part gpt-5 rollout explicit focu make output safer less prone manipul .',\n",
              " 'openai describ safe-complet approach teach model gener safe redirect non-action partial answer instead outright refus .',\n",
              " 'thi reduc friction user experi keep system help without produc disallow content .',\n",
              " 'control experi report openai show safe-complet train reduc sever certain riski output maintain use .',\n",
              " 'openai also report progress detect reduc scheme behavior , model might feign complet task attempt subvert control .',\n",
              " 'while risk elimin , compani claim meaning improv gpt-5 compar prior model .',\n",
              " 'alongsid architectur safeti advanc , openai highlight real-world empir improv .',\n",
              " 'gpt-5 show measur gain speed , accuraci , effici , particularli code reason benchmark .',\n",
              " 'it claim state-of-the-art result sever softwar engin metric achiev better tradeoff reason power comput cost .',\n",
              " 'in practic , gpt-5 reportedli use fewer token fewer extern tool call solv complex code task compar previou high-reason model .',\n",
              " 'thi combin capabl effici make gpt-5 directli attract develop enterpris .',\n",
              " 'user also report gpt-5 hallucin less scenario requir chain reason .',\n",
              " 'while hallucin elimin , improv reason train post-train help mitig , especi structur problem solv .',\n",
              " 'the system card support research document gain acknowledg limit open challeng .',\n",
              " 'look ahead , gpt-5 ’ design suggest sever implic futur openai ai develop broadli .',\n",
              " 'one product “ think ” model .',\n",
              " 'gpt-5 ’ hybrid architectur point toward futur ai product routin includ multi-mod system router match comput need .',\n",
              " 'chatgpt api product like expos option fast versu deep reason , give develop finer control latency-versus-accuraci tradeoff .',\n",
              " 'thi make ai tool flexibl better align practic workflow .',\n",
              " 'anoth implic scale agent autom .',\n",
              " 'as model get better orchestr tool manag memori , agent workflow move demo research prototyp product usag across industri .',\n",
              " 'autonom assist perform multi-step task increasingli appear custom support , research develop , softwar engin , oper .',\n",
              " 'ai becom deepli integr busi process , mere use text interfac .',\n",
              " 'safeti also set becom first-class engin prioriti .',\n",
              " 'openai ’ public work safe-complet , scheme detect , system-level mitig impli safeti engin tightli integr capabl gain .',\n",
              " 'for adopt , mean richer control sandbox , tool-permiss system , configur safeti polici , especi enterpris context .',\n",
              " 'thi align broader trend toward respons ai develop , usabl must pair safeguard .',\n",
              " 'commerci regulatori pressur also shape openai ’ trajectori .',\n",
              " 'as model becom power wide adopt , openai face increas scrutini regul , custom , public around issu like misus , copyright , econom disrupt .',\n",
              " 'the compani need balanc open capabl develop layer access control transpar measur maintain trust .',\n",
              " 'it futur involv technic innov also activ engag govern polici .',\n",
              " 'final , research frontier remain wide open .',\n",
              " 'despit gpt-5 ’ advanc , challeng persist : fulli elimin hallucin , achiev robust verifi reason , enabl composit tool use across long horizon , ensur provabl align .',\n",
              " 'openai ’ approach—a blend scale , architectur special , post-train alignment—off one path forward , academ industri commun like experi altern symbol hybrid , neural theorem prove , causal model , new verif method .',\n",
              " 'the jump gpt-4 gpt-4.5 gpt-5 read less like singl leap like system evolut .',\n",
              " 'smarter rout , dedic reason brain , tighter tool integr , longer context window , new safety-first train techniqu contribut make gpt-5 use real world .',\n",
              " 'it faster everyday task , deeper complex problem , safer mani practic scenario , still foreground unresolv challeng guid research polici year come .',\n",
              " 'for develop organ , immedi impact pragmat : better product tool , richer agent capabl , grow set control safe deploy .',\n",
              " 'for broader field , gpt-5 repres next phase make ai larger , compos , control , context-awar .']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2=sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "rIE7N7iqN59L"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentence2)):\n",
        "   words=nltk.word_tokenize(sentence2[i])\n",
        "   words=[snw.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "   sentence2[i]=\" \".join(words)"
      ],
      "metadata": {
        "id": "_GjShkV9OGFD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oghj87pdXwj6",
        "outputId": "0e05b2d9-68a8-4e48-9950-c801bfd36a58"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['openai ’ jump gpt-4 ( interim gpt-4.5 ) gpt-5 singl “ bigger model ” upgrad .',\n",
              " 'it systems-level redesign : combin model special , rout , new safeti post-train strategi system answer quick routin queri deliber deepli task demand higher-fidel reason .',\n",
              " 'in plain term , gpt-5 present unifi system contain fast “ everyday ” model deeper “ reason ” model , plus low-lat router decid mode use depend task complex tool need .',\n",
              " 'that combin let system econom respons easi task reserv expens reason comput hard one .',\n",
              " 'this hybrid approach reflect two complementari trend field .',\n",
              " 'one continu benefit scale unsupervis pre-training—bigg , divers data comput improv pattern recognit , fluent generat , general world knowledg .',\n",
              " 'this gpt-4.5 made gain .',\n",
              " 'the trend target , explicit train reason tool-us , teach model “ think ” chain thought , stepwis solv , tool orchestr rather mere pattern-match .',\n",
              " 'gpt-5 thread axe : effici front-lin model fast answer deeper , slower reason brain complex , multi-step problem .',\n",
              " 'instead one monolith model tune task , gpt-5 use suit compon : fast respond deeper reason , onlin router dynam pick right compon .',\n",
              " 'this reduc unnecessari comput improv averag latenc preserv strong perform hard task .',\n",
              " 'that architectur central openai ’ claim improv speed “ think need . ” openai also invest heavili reason train .',\n",
              " 'the compani design regim encourag model produc explicit intermedi reason step use tool chain effectively—help math , code , structur task .',\n",
              " 'the reason model gpt-5 explicit built tackl multi-step problem reliabl , help reduc common failur mode like incorrect intermedi step shallow , superfici answer .',\n",
              " 'anoth central advanc tool agent integr .',\n",
              " 'gpt-5 engin smoother reliabl tool invoc , whether api , calcul , code execut , agent workflow .',\n",
              " 'it longer “ give answer ” “ orchestr sequenc tool , rememb past interact , adapt . ” this make far stronger code collabor , debugg , workflow assist , call extern servic rememb context crucial .',\n",
              " 'earli benchmark releas openai show sizabl gain softwar engin task , posit gpt-5 reason partner technic problem-solv .',\n",
              " 'the model also benefit scale context memori .',\n",
              " 'openai expand oper context window improv state manag enabl longer , coher interact .',\n",
              " 'this matter handl long document , multi-fil codebas , extend agent convers .',\n",
              " 'larger context mean system condit much histori extern context without lose coher .',\n",
              " 'openai ’ api announc system card describ gpt-5 rememb leverag signific inform previous model , reduc need re-prompt allow natur extend workflow .',\n",
              " 'post-train align innov distinguish gpt-5 .',\n",
              " 'beyond raw capabl , openai emphas techniqu shape model behavior pretrain : target safeti train , “ safe-complet ” strategi prefer redirect blunt refus , new method detect reduc decept scheme behavior .',\n",
              " 'these move aim make model usabl product reduc danger failur mode .',\n",
              " 'the compani highlight post-train process help balanc help safeti , improv trust real-world deploy .',\n",
              " 'one consequenti part gpt-5 rollout explicit focus make output safer less prone manipul .',\n",
              " 'openai describ safe-complet approach teach model generat safe redirect non-action partial answer instead outright refus .',\n",
              " 'this reduc friction user experi keep system help without produc disallow content .',\n",
              " 'control experi report openai show safe-complet train reduc sever certain riski output maintain use .',\n",
              " 'openai also report progress detect reduc scheme behavior , model might feign complet task attempt subvert control .',\n",
              " 'while risk elimin , compani claim meaning improv gpt-5 compar prior model .',\n",
              " 'alongsid architectur safeti advanc , openai highlight real-world empir improv .',\n",
              " 'gpt-5 show measur gain speed , accuraci , effici , particular code reason benchmark .',\n",
              " 'it claim state-of-the-art result sever softwar engin metric achiev better tradeoff reason power comput cost .',\n",
              " 'in practic , gpt-5 report use fewer token fewer extern tool call solv complex code task compar previous high-reason model .',\n",
              " 'this combin capabl effici make gpt-5 direct attract develop enterpris .',\n",
              " 'user also report gpt-5 hallucin less scenario requir chain reason .',\n",
              " 'while hallucin elimin , improv reason train post-train help mitig , especi structur problem solv .',\n",
              " 'the system card support research document gain acknowledg limit open challeng .',\n",
              " 'look ahead , gpt-5 ’ design suggest sever implic futur openai ai develop broad .',\n",
              " 'one product “ think ” model .',\n",
              " 'gpt-5 ’ hybrid architectur point toward futur ai product routin includ multi-mod system router match comput need .',\n",
              " 'chatgpt api product like expos option fast versus deep reason , give develop finer control latency-versus-accuraci tradeoff .',\n",
              " 'this make ai tool flexibl better align practic workflow .',\n",
              " 'anoth implic scale agent autom .',\n",
              " 'as model get better orchestr tool manag memori , agent workflow move demo research prototyp product usag across industri .',\n",
              " 'autonom assist perform multi-step task increas appear custom support , research develop , softwar engin , oper .',\n",
              " 'ai becom deepli integr busi process , mere use text interfac .',\n",
              " 'safeti also set becom first-class engin prioriti .',\n",
              " 'openai ’ public work safe-complet , scheme detect , system-level mitig impli safeti engin tight integr capabl gain .',\n",
              " 'for adopt , mean richer control sandbox , tool-permiss system , configur safeti polici , especi enterpris context .',\n",
              " 'this align broader trend toward respons ai develop , usabl must pair safeguard .',\n",
              " 'commerci regulatori pressur also shape openai ’ trajectori .',\n",
              " 'as model becom power wide adopt , openai face increas scrutini regul , custom , public around issu like misus , copyright , econom disrupt .',\n",
              " 'the compani need balanc open capabl develop layer access control transpar measur maintain trust .',\n",
              " 'it futur involv technic innov also activ engag govern polici .',\n",
              " 'final , research frontier remain wide open .',\n",
              " 'despit gpt-5 ’ advanc , challeng persist : fulli elimin hallucin , achiev robust verifi reason , enabl composit tool use across long horizon , ensur provabl align .',\n",
              " 'openai ’ approach—a blend scale , architectur special , post-train alignment—off one path forward , academ industri communiti like experi altern symbol hybrid , neural theorem prove , causal model , new verif method .',\n",
              " 'the jump gpt-4 gpt-4.5 gpt-5 read less like singl leap like system evolut .',\n",
              " 'smarter rout , dedic reason brain , tighter tool integr , longer context window , new safety-first train techniqu contribut make gpt-5 use real world .',\n",
              " 'it faster everyday task , deeper complex problem , safer mani practic scenario , still foreground unresolv challeng guid research polici year come .',\n",
              " 'for develop organ , immedi impact pragmat : better product tool , richer agent capabl , grow set control safe deploy .',\n",
              " 'for broader field , gpt-5 repres next phase make ai larger , compos , control , context-awar .']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence3=sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "rEcSUIzmYKIX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentence3)):\n",
        "  words=nltk.word_tokenize(sentence[i])\n",
        "  words=[lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentence3[i]=\" \".join(words)"
      ],
      "metadata": {
        "id": "9JVELFU5XxT8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utdm_GyaYr8U",
        "outputId": "687d12fc-3773-4d7d-d92f-64ac76d14a95"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['openai ’ jump gpt-4 ( interim gpt-4.5 ) gpt-5 singl “ bigger model ” upgrad .',\n",
              " 'systems-level redesign : combin model special , rout , new safeti post-train strategi system answer quickli routin queri deliber deepli task demand higher-fidel reason .',\n",
              " 'plain term , gpt-5 present unifi system contain fast “ everyday ” model deeper “ reason ” model , plu low-lat router decid mode use depend task complex tool need .',\n",
              " 'combin let system econom respons easi task reserv expens reason comput hard one .',\n",
              " 'thi hybrid approach reflect two complementari trend field .',\n",
              " 'one continu benefit scale unsupervis pre-training—bigg , divers data comput improv pattern recognit , fluent gener , gener world knowledg .',\n",
              " 'thi gpt-4.5 make gain .',\n",
              " 'trend target , explicit train reason tool-us , teach model “ think ” chain think , stepwis solv , tool orchestr rather mere pattern-match .',\n",
              " 'gpt-5 thread axe : effici front-lin model fast answer deeper , slower reason brain complex , multi-step problem .',\n",
              " 'instead one monolith model tune task , gpt-5 use suit compon : fast respond deeper reason , onlin router dynam pick right compon .',\n",
              " 'thi reduc unnecessari comput improv averag latenc preserv strong perform hard task .',\n",
              " 'architectur central openai ’ claim improv speed “ think need . ” openai also invest heavili reason train .',\n",
              " 'compani design regim encourag model produc explicit intermedi reason step use tool chain effectively—help math , code , structur task .',\n",
              " 'reason model gpt-5 explicitli build tackl multi-step problem reliabl , help reduc common failur mode like incorrect intermedi step shallow , superfici answer .',\n",
              " 'anoth central advanc tool agent integr .',\n",
              " 'gpt-5 engin smoother reliabl tool invoc , whether api , calcul , code execut , agent workflow .',\n",
              " 'longer “ give answer ” “ orchestr sequenc tool , rememb past interact , adapt . ” thi make far stronger code collabor , debugg , workflow assist , call extern servic rememb context crucial .',\n",
              " 'earli benchmark releas openai show sizabl gain softwar engin task , posit gpt-5 reason partner technic problem-solv .',\n",
              " 'model also benefit scale context memori .',\n",
              " 'openai expand oper context window improv state manag enabl longer , coher interact .',\n",
              " 'thi matter handl long document , multi-fil codebas , extend agent convers .',\n",
              " 'larger context mean system condit much histori extern context without lose coher .',\n",
              " 'openai ’ api announc system card describ gpt-5 rememb leverag significantli inform previou model , reduc need re-prompt allow natur extend workflow .',\n",
              " 'post-train align innov distinguish gpt-5 .',\n",
              " 'beyond raw capabl , openai emphas techniqu shape model behavior pretrain : target safeti train , “ safe-complet ” strategi prefer redirect blunt refus , new method detect reduc decept scheme behavior .',\n",
              " 'move aim make model usabl product reduc danger failur mode .',\n",
              " 'compani highlight post-train process help balanc help safeti , improv trust real-world deploy .',\n",
              " 'one consequenti part gpt-5 rollout explicit focu make output safer less prone manipul .',\n",
              " 'openai describ safe-complet approach teach model gener safe redirect non-action partial answer instead outright refus .',\n",
              " 'thi reduc friction user experi keep system help without produc disallow content .',\n",
              " 'control experi report openai show safe-complet train reduc sever certain riski output maintain use .',\n",
              " 'openai also report progress detect reduc scheme behavior , model might feign complet task attempt subvert control .',\n",
              " 'risk elimin , compani claim mean improv gpt-5 compar prior model .',\n",
              " 'alongsid architectur safeti advanc , openai highlight real-world empir improv .',\n",
              " 'gpt-5 show measur gain speed , accuraci , effici , particularli code reason benchmark .',\n",
              " 'claim state-of-the-art result sever softwar engin metric achiev better tradeoff reason power comput cost .',\n",
              " 'practic , gpt-5 reportedli use fewer token fewer extern tool call solv complex code task compar previou high-reason model .',\n",
              " 'thi combin capabl effici make gpt-5 directli attract develop enterpris .',\n",
              " 'user also report gpt-5 hallucin less scenario requir chain reason .',\n",
              " 'hallucin elimin , improv reason train post-train help mitig , especi structur problem solv .',\n",
              " 'system card support research document gain acknowledg limit open challeng .',\n",
              " 'look ahead , gpt-5 ’ design suggest sever implic futur openai ai develop broadli .',\n",
              " 'one product “ think ” model .',\n",
              " 'gpt-5 ’ hybrid architectur point toward futur ai product routin includ multi-mod system router match comput need .',\n",
              " 'chatgpt api product like expos option fast versu deep reason , give develop finer control latency-versus-accuraci tradeoff .',\n",
              " 'thi make ai tool flexibl better align practic workflow .',\n",
              " 'anoth implic scale agent autom .',\n",
              " 'model get better orchestr tool manag memori , agent workflow move demo research prototyp product usag across industri .',\n",
              " 'autonom assist perform multi-step task increasingli appear custom support , research develop , softwar engin , oper .',\n",
              " 'ai becom deepli integr busi process , mere use text interfac .',\n",
              " 'safeti also set becom first-class engin prioriti .',\n",
              " 'openai ’ public work safe-complet , scheme detect , system-level mitig impli safeti engin tightli integr capabl gain .',\n",
              " 'adopt , mean richer control sandbox , tool-permiss system , configur safeti polici , especi enterpris context .',\n",
              " 'thi align broader trend toward respons ai develop , usabl must pair safeguard .',\n",
              " 'commerci regulatori pressur also shape openai ’ trajectori .',\n",
              " 'model becom power wide adopt , openai face increas scrutini regul , custom , public around issu like misus , copyright , econom disrupt .',\n",
              " 'compani need balanc open capabl develop layer access control transpar measur maintain trust .',\n",
              " 'futur involv technic innov also activ engag govern polici .',\n",
              " 'final , research frontier remain wide open .',\n",
              " 'despit gpt-5 ’ advanc , challeng persist : fulli elimin hallucin , achiev robust verifi reason , enabl composit tool use across long horizon , ensur provabl align .',\n",
              " 'openai ’ approach—a blend scale , architectur special , post-train alignment—off one path forward , academ industri commun like experi altern symbol hybrid , neural theorem prove , causal model , new verif method .',\n",
              " 'jump gpt-4 gpt-4.5 gpt-5 read less like singl leap like system evolut .',\n",
              " 'smarter rout , dedic reason brain , tighter tool integr , longer context window , new safety-first train techniqu contribut make gpt-5 use real world .',\n",
              " 'faster everyday task , deeper complex problem , safer mani practic scenario , still foreground unresolv challeng guid research polici year come .',\n",
              " 'develop organ , immedi impact pragmat : better product tool , richer agent capabl , grow set control safe deploy .',\n",
              " 'broader field , gpt-5 repres next phase make ai larger , compos , control , context-awar .']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Speech Tagging\n",
        "speech=paragraph"
      ],
      "metadata": {
        "id": "xnrkNsXCYuFj"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp8ZfyYSZKEI",
        "outputId": "10bee7ee-bbf3-4ed5-a5e4-012f8cde03dd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech_tokens=sent_tokenize(speech)"
      ],
      "metadata": {
        "id": "ipt3Mg_oZLID"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "for i in range(len(speech_tokens)):\n",
        "   words= nltk.word_tokenize(speech_tokens[i])\n",
        "   words= [word for word in words if word not in set(stopwords.words('english'))]\n",
        "   pos_tags=nltk.pos_tag(words)\n",
        "   print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74kswfQZheR",
        "outputId": "f01e1586-4176-4593-94a5-4c31ef44152d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('OpenAI', 'NNP'), ('’', 'NNP'), ('jump', 'NN'), ('GPT-4', 'NNP'), ('(', '('), ('interim', 'JJ'), ('GPT-4.5', 'NNP'), (')', ')'), ('GPT-5', 'NNP'), ('single', 'JJ'), ('“', 'NNP'), ('bigger', 'JJR'), ('model', 'NN'), ('”', 'NN'), ('upgrade', 'NN'), ('.', '.')]\n",
            "[('It', 'PRP'), ('systems-level', 'JJ'), ('redesign', 'NN'), (':', ':'), ('combining', 'VBG'), ('model', 'NN'), ('specialization', 'NN'), (',', ','), ('routing', 'VBG'), (',', ','), ('new', 'JJ'), ('safety', 'NN'), ('post-training', 'NN'), ('strategies', 'NNS'), ('system', 'NN'), ('answer', 'VBP'), ('quickly', 'RB'), ('routine', 'JJ'), ('queries', 'NNS'), ('deliberate', 'VBP'), ('deeply', 'RB'), ('tasks', 'JJ'), ('demand', 'NN'), ('higher-fidelity', 'NN'), ('reasoning', 'NN'), ('.', '.')]\n",
            "[('In', 'IN'), ('plain', 'NN'), ('terms', 'NNS'), (',', ','), ('GPT-5', 'NNP'), ('presented', 'VBD'), ('unified', 'JJ'), ('system', 'NN'), ('contains', 'VBZ'), ('fast', 'RB'), ('“', 'JJ'), ('everyday', 'JJ'), ('”', 'NNP'), ('model', 'NN'), ('deeper', 'NN'), ('“', 'NNP'), ('reasoning', 'VBG'), ('”', 'JJ'), ('model', 'NN'), (',', ','), ('plus', 'CC'), ('low-latency', 'JJ'), ('router', 'NN'), ('decides', 'NNS'), ('mode', 'VBP'), ('use', 'IN'), ('depending', 'VBG'), ('task', 'NN'), ('complexity', 'NN'), ('tool', 'NN'), ('needs', 'NNS'), ('.', '.')]\n",
            "[('That', 'DT'), ('combination', 'NN'), ('lets', 'VBZ'), ('system', 'NN'), ('economical', 'JJ'), ('responsive', 'JJ'), ('easy', 'JJ'), ('tasks', 'NNS'), ('reserving', 'VBG'), ('expensive', 'JJ'), ('reasoning', 'VBG'), ('compute', 'JJ'), ('hard', 'JJ'), ('ones', 'NNS'), ('.', '.')]\n",
            "[('This', 'DT'), ('hybrid', 'JJ'), ('approach', 'NN'), ('reflects', 'VBZ'), ('two', 'CD'), ('complementary', 'JJ'), ('trends', 'NNS'), ('field', 'NN'), ('.', '.')]\n",
            "[('One', 'CD'), ('continued', 'JJ'), ('benefit', 'NN'), ('scaling', 'VBG'), ('unsupervised', 'JJ'), ('pre-training—bigger', 'NN'), (',', ','), ('diverse', 'JJ'), ('data', 'NNS'), ('compute', 'NN'), ('improves', 'VBZ'), ('pattern', 'JJ'), ('recognition', 'NN'), (',', ','), ('fluent', 'JJ'), ('generation', 'NN'), (',', ','), ('general', 'JJ'), ('world', 'NN'), ('knowledge', 'NN'), ('.', '.')]\n",
            "[('This', 'DT'), ('GPT-4.5', 'NNP'), ('made', 'VBD'), ('gains', 'NNS'), ('.', '.')]\n",
            "[('The', 'DT'), ('trend', 'NN'), ('targeted', 'VBD'), (',', ','), ('explicit', 'JJ'), ('training', 'VBG'), ('reasoning', 'VBG'), ('tool-use', 'NN'), (',', ','), ('teaching', 'VBG'), ('models', 'NNS'), ('“', 'NNP'), ('think', 'VBP'), ('”', 'NNP'), ('chains', 'NNS'), ('thought', 'VBD'), (',', ','), ('stepwise', 'NN'), ('solving', 'NN'), (',', ','), ('tool', 'NN'), ('orchestration', 'NN'), ('rather', 'RB'), ('merely', 'RB'), ('pattern-matching', 'JJ'), ('.', '.')]\n",
            "[('GPT-5', 'NNP'), ('threads', 'NNS'), ('axes', 'NNS'), (':', ':'), ('efficient', 'JJ'), ('front-line', 'JJ'), ('model', 'NN'), ('fast', 'NN'), ('answers', 'NNS'), ('deeper', 'RBR'), (',', ','), ('slower', 'JJR'), ('reasoning', 'VBG'), ('brain', 'NN'), ('complex', 'JJ'), (',', ','), ('multi-step', 'JJ'), ('problems', 'NNS'), ('.', '.')]\n",
            "[('Instead', 'RB'), ('one', 'CD'), ('monolithic', 'JJ'), ('model', 'NN'), ('tuned', 'VBD'), ('tasks', 'NNS'), (',', ','), ('GPT-5', 'NNP'), ('uses', 'VBZ'), ('suite', 'JJ'), ('components', 'NNS'), (':', ':'), ('fast', 'RB'), ('responder', 'VB'), ('deeper', 'JJR'), ('reasoner', 'NN'), (',', ','), ('online', 'VBP'), ('router', 'NN'), ('dynamically', 'RB'), ('picks', 'VBZ'), ('right', 'JJ'), ('component', 'NN'), ('.', '.')]\n",
            "[('This', 'DT'), ('reduces', 'VBZ'), ('unnecessary', 'JJ'), ('compute', 'NN'), ('improves', 'VBZ'), ('average', 'JJ'), ('latency', 'NN'), ('preserving', 'VBG'), ('strong', 'JJ'), ('performance', 'NN'), ('hard', 'JJ'), ('tasks', 'NNS'), ('.', '.')]\n",
            "[('That', 'DT'), ('architecture', 'JJ'), ('central', 'JJ'), ('OpenAI', 'NNP'), ('’', 'NNP'), ('claims', 'VBZ'), ('improved', 'VBN'), ('speed', 'NN'), ('“', 'NN'), ('thinking', 'VBG'), ('needed.', 'JJ'), ('”', 'NNP'), ('OpenAI', 'NNP'), ('also', 'RB'), ('invested', 'VBD'), ('heavily', 'RB'), ('reasoning', 'VBG'), ('training', 'NN'), ('.', '.')]\n",
            "[('The', 'DT'), ('company', 'NN'), ('designed', 'VBN'), ('regimes', 'NNS'), ('encourage', 'VB'), ('model', 'NN'), ('produce', 'NN'), ('explicit', 'JJ'), ('intermediate', 'JJ'), ('reasoning', 'VBG'), ('steps', 'NNS'), ('use', 'VBP'), ('tool', 'NN'), ('chains', 'NNS'), ('effectively—helpful', 'JJ'), ('math', 'NN'), (',', ','), ('coding', 'VBG'), (',', ','), ('structured', 'JJ'), ('tasks', 'NNS'), ('.', '.')]\n",
            "[('The', 'DT'), ('reasoning', 'VBG'), ('model', 'NN'), ('GPT-5', 'NNP'), ('explicitly', 'RB'), ('built', 'VBD'), ('tackle', 'JJ'), ('multi-step', 'NN'), ('problems', 'NNS'), ('reliably', 'RB'), (',', ','), ('helping', 'VBG'), ('reduce', 'VB'), ('common', 'JJ'), ('failure', 'NN'), ('modes', 'NNS'), ('like', 'IN'), ('incorrect', 'JJ'), ('intermediate', 'JJ'), ('steps', 'NNS'), ('shallow', 'RB'), (',', ','), ('superficial', 'JJ'), ('answers', 'NNS'), ('.', '.')]\n",
            "[('Another', 'DT'), ('central', 'JJ'), ('advancement', 'NN'), ('tool', 'NN'), ('agent', 'NN'), ('integration', 'NN'), ('.', '.')]\n",
            "[('GPT-5', 'NNP'), ('engineered', 'VBD'), ('smoother', 'RBR'), ('reliable', 'JJ'), ('tool', 'NN'), ('invocation', 'NN'), (',', ','), ('whether', 'IN'), ('APIs', 'NNP'), (',', ','), ('calculators', 'NNS'), (',', ','), ('code', 'NN'), ('execution', 'NN'), (',', ','), ('agentic', 'JJ'), ('workflows', 'NNS'), ('.', '.')]\n",
            "[('It', 'PRP'), ('longer', 'RBR'), ('“', 'JJ'), ('give', 'VB'), ('answer', 'NN'), ('”', 'NNP'), ('“', 'NNP'), ('orchestrate', 'JJ'), ('sequence', 'NN'), ('tools', 'NNS'), (',', ','), ('remember', 'VB'), ('past', 'JJ'), ('interactions', 'NNS'), (',', ','), ('adapt.', 'RB'), ('”', 'IN'), ('This', 'DT'), ('makes', 'VBZ'), ('far', 'RB'), ('stronger', 'JJR'), ('coding', 'VBG'), ('collaborator', 'NN'), (',', ','), ('debugger', 'NN'), (',', ','), ('workflow', 'NN'), ('assistant', 'NN'), (',', ','), ('calling', 'VBG'), ('external', 'JJ'), ('services', 'NNS'), ('remembering', 'VBG'), ('context', 'JJ'), ('crucial', 'NN'), ('.', '.')]\n",
            "[('Early', 'RB'), ('benchmarks', 'NNS'), ('released', 'VBD'), ('OpenAI', 'NNP'), ('show', 'NN'), ('sizable', 'JJ'), ('gains', 'NNS'), ('software', 'NN'), ('engineering', 'NN'), ('tasks', 'NNS'), (',', ','), ('positioning', 'VBG'), ('GPT-5', 'JJ'), ('reasoning', 'NN'), ('partner', 'NN'), ('technical', 'JJ'), ('problem-solver', 'NN'), ('.', '.')]\n",
            "[('The', 'DT'), ('model', 'NN'), ('also', 'RB'), ('benefits', 'NNS'), ('scale', 'JJ'), ('context', 'JJ'), ('memory', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('expanded', 'VBD'), ('operational', 'JJ'), ('context', 'NN'), ('windows', 'NNS'), ('improved', 'VBN'), ('state', 'NN'), ('management', 'NN'), ('enable', 'JJ'), ('longer', 'NN'), (',', ','), ('coherent', 'JJ'), ('interactions', 'NNS'), ('.', '.')]\n",
            "[('This', 'DT'), ('matters', 'NNS'), ('handling', 'VBG'), ('long', 'JJ'), ('documents', 'NNS'), (',', ','), ('multi-file', 'JJ'), ('codebases', 'NNS'), (',', ','), ('extended', 'VBD'), ('agent', 'NN'), ('conversations', 'NNS'), ('.', '.')]\n",
            "[('Larger', 'NNP'), ('context', 'NN'), ('means', 'VBZ'), ('system', 'NN'), ('condition', 'NN'), ('much', 'JJ'), ('history', 'NN'), ('external', 'JJ'), ('context', 'NN'), ('without', 'IN'), ('losing', 'VBG'), ('coherence', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('’', 'NNP'), ('API', 'NNP'), ('announcements', 'NNS'), ('system', 'NN'), ('card', 'JJ'), ('describe', 'VBZ'), ('GPT-5', 'NNP'), ('remember', 'NN'), ('leverage', 'NN'), ('significantly', 'RB'), ('information', 'NN'), ('previous', 'JJ'), ('models', 'NNS'), (',', ','), ('reducing', 'VBG'), ('need', 'JJ'), ('re-prompt', 'JJ'), ('allowing', 'VBG'), ('natural', 'JJ'), ('extended', 'VBN'), ('workflows', 'NNS'), ('.', '.')]\n",
            "[('Post-training', 'JJ'), ('alignment', 'NN'), ('innovations', 'NNS'), ('distinguish', 'JJ'), ('GPT-5', 'NNP'), ('.', '.')]\n",
            "[('Beyond', 'IN'), ('raw', 'JJ'), ('capability', 'NN'), (',', ','), ('OpenAI', 'NNP'), ('emphasized', 'VBD'), ('techniques', 'NNS'), ('shape', 'VBP'), ('model', 'NN'), ('behavior', 'NN'), ('pretraining', 'NN'), (':', ':'), ('targeted', 'VBN'), ('safety', 'NN'), ('training', 'NN'), (',', ','), ('“', 'JJ'), ('safe-completion', 'NN'), ('”', 'NN'), ('strategies', 'NNS'), ('prefer', 'VBP'), ('redirection', 'NN'), ('blunt', 'NN'), ('refusals', 'NNS'), (',', ','), ('new', 'JJ'), ('methods', 'NNS'), ('detect', 'VBP'), ('reduce', 'VB'), ('deceptive', 'JJ'), ('scheming', 'NN'), ('behaviors', 'NNS'), ('.', '.')]\n",
            "[('These', 'DT'), ('moves', 'NNS'), ('aim', 'VBP'), ('make', 'VBP'), ('model', 'NN'), ('usable', 'JJ'), ('production', 'NN'), ('reducing', 'VBG'), ('dangerous', 'JJ'), ('failure', 'NN'), ('modes', 'NNS'), ('.', '.')]\n",
            "[('The', 'DT'), ('company', 'NN'), ('highlights', 'VBZ'), ('post-training', 'NN'), ('processes', 'NNS'), ('help', 'VBP'), ('balance', 'VB'), ('helpfulness', 'JJ'), ('safety', 'NN'), (',', ','), ('improving', 'VBG'), ('trust', 'JJ'), ('real-world', 'JJ'), ('deployment', 'NN'), ('.', '.')]\n",
            "[('One', 'CD'), ('consequential', 'JJ'), ('parts', 'NNS'), ('GPT-5', 'NNP'), ('rollout', 'NN'), ('explicit', 'JJ'), ('focus', 'NN'), ('making', 'VBG'), ('outputs', 'NNS'), ('safer', 'RB'), ('less', 'JJR'), ('prone', 'JJ'), ('manipulation', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('describes', 'VBZ'), ('safe-completion', 'NN'), ('approach', 'NN'), ('teaching', 'VBG'), ('models', 'NNS'), ('generate', 'VBP'), ('safe', 'JJ'), ('redirections', 'NNS'), ('non-actionable', 'JJ'), ('partial', 'JJ'), ('answers', 'NNS'), ('instead', 'RB'), ('outright', 'JJ'), ('refusals', 'NNS'), ('.', '.')]\n",
            "[('This', 'DT'), ('reduces', 'VBZ'), ('friction', 'NN'), ('user', 'NN'), ('experience', 'NN'), ('keeps', 'VBZ'), ('systems', 'NNS'), ('helpful', 'JJ'), ('without', 'IN'), ('producing', 'VBG'), ('disallowed', 'VBN'), ('content', 'NN'), ('.', '.')]\n",
            "[('Controlled', 'VBN'), ('experiments', 'NNS'), ('reported', 'VBD'), ('OpenAI', 'NNP'), ('show', 'NN'), ('safe-completion', 'NN'), ('training', 'NN'), ('reduce', 'VB'), ('severity', 'NN'), ('certain', 'JJ'), ('risky', 'JJ'), ('outputs', 'NNS'), ('maintaining', 'VBG'), ('usefulness', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('also', 'RB'), ('reports', 'VBZ'), ('progress', 'NN'), ('detecting', 'VBG'), ('reducing', 'VBG'), ('scheming', 'VBG'), ('behaviors', 'NNS'), (',', ','), ('model', 'NN'), ('might', 'MD'), ('feign', 'VB'), ('completion', 'NN'), ('task', 'NN'), ('attempt', 'NN'), ('subvert', 'NN'), ('controls', 'NNS'), ('.', '.')]\n",
            "[('While', 'IN'), ('risks', 'NNS'), ('eliminated', 'VBN'), (',', ','), ('company', 'NN'), ('claims', 'NNS'), ('meaningful', 'JJ'), ('improvements', 'NNS'), ('GPT-5', 'JJ'), ('compared', 'VBN'), ('prior', 'JJ'), ('models', 'NNS'), ('.', '.')]\n",
            "[('Alongside', 'RB'), ('architectural', 'JJ'), ('safety', 'NN'), ('advances', 'NNS'), (',', ','), ('OpenAI', 'NNP'), ('highlights', 'VBZ'), ('real-world', 'JJ'), ('empirical', 'JJ'), ('improvements', 'NNS'), ('.', '.')]\n",
            "[('GPT-5', 'NN'), ('shows', 'NNS'), ('measurable', 'JJ'), ('gains', 'NNS'), ('speed', 'NN'), (',', ','), ('accuracy', 'NN'), (',', ','), ('efficiency', 'NN'), (',', ','), ('particularly', 'RB'), ('coding', 'VBG'), ('reasoning', 'VBG'), ('benchmarks', 'NNS'), ('.', '.')]\n",
            "[('It', 'PRP'), ('claims', 'VBZ'), ('state-of-the-art', 'JJ'), ('results', 'NNS'), ('several', 'JJ'), ('software', 'NN'), ('engineering', 'NN'), ('metrics', 'NNS'), ('achieves', 'VBZ'), ('better', 'JJR'), ('tradeoff', 'NN'), ('reasoning', 'VBG'), ('power', 'NN'), ('compute', 'NN'), ('cost', 'NN'), ('.', '.')]\n",
            "[('In', 'IN'), ('practice', 'NN'), (',', ','), ('GPT-5', 'NNP'), ('reportedly', 'RB'), ('uses', 'VBZ'), ('fewer', 'JJR'), ('tokens', 'NNS'), ('fewer', 'JJR'), ('external', 'JJ'), ('tool', 'NN'), ('calls', 'VBZ'), ('solve', 'VBP'), ('complex', 'JJ'), ('coding', 'NN'), ('tasks', 'NNS'), ('compared', 'VBN'), ('previous', 'JJ'), ('high-reasoning', 'JJ'), ('models', 'NNS'), ('.', '.')]\n",
            "[('This', 'DT'), ('combination', 'NN'), ('capability', 'NN'), ('efficiency', 'NN'), ('makes', 'VBZ'), ('GPT-5', 'NNP'), ('directly', 'RB'), ('attractive', 'JJ'), ('developers', 'NNS'), ('enterprises', 'NNS'), ('.', '.')]\n",
            "[('Users', 'NNS'), ('also', 'RB'), ('report', 'VBP'), ('GPT-5', 'NNP'), ('hallucinates', 'VBZ'), ('less', 'JJR'), ('scenarios', 'NNS'), ('requiring', 'VBG'), ('chained', 'VBD'), ('reasoning', 'VBG'), ('.', '.')]\n",
            "[('While', 'IN'), ('hallucinations', 'NNS'), ('eliminated', 'VBN'), (',', ','), ('improvements', 'NNS'), ('reasoning', 'VBG'), ('training', 'VBG'), ('post-training', 'JJ'), ('help', 'NN'), ('mitigate', 'VB'), (',', ','), ('especially', 'RB'), ('structured', 'VBN'), ('problem', 'NN'), ('solving', 'NN'), ('.', '.')]\n",
            "[('The', 'DT'), ('system', 'NN'), ('card', 'NN'), ('supporting', 'VBG'), ('research', 'NN'), ('document', 'NN'), ('gains', 'NNS'), ('acknowledging', 'VBG'), ('limitations', 'NNS'), ('open', 'JJ'), ('challenges', 'NNS'), ('.', '.')]\n",
            "[('Looking', 'VBG'), ('ahead', 'RB'), (',', ','), ('GPT-5', 'NNP'), ('’', 'NNP'), ('design', 'NN'), ('suggests', 'VBZ'), ('several', 'JJ'), ('implications', 'NNS'), ('future', 'JJ'), ('OpenAI', 'NNP'), ('AI', 'NNP'), ('development', 'NN'), ('broadly', 'RB'), ('.', '.')]\n",
            "[('One', 'CD'), ('productization', 'NN'), ('“', 'NN'), ('thinking', 'VBG'), ('”', 'JJ'), ('models', 'NNS'), ('.', '.')]\n",
            "[('GPT-5', 'NNP'), ('’', 'NNP'), ('hybrid', 'JJ'), ('architecture', 'NN'), ('points', 'NNS'), ('toward', 'IN'), ('future', 'JJ'), ('AI', 'NNP'), ('products', 'NNS'), ('routinely', 'RB'), ('include', 'VBP'), ('multi-mode', 'JJ'), ('systems', 'NNS'), ('routers', 'NNS'), ('match', 'VBP'), ('compute', 'NN'), ('need', 'NN'), ('.', '.')]\n",
            "[('ChatGPT', 'NNP'), ('API', 'NNP'), ('products', 'NNS'), ('likely', 'RB'), ('expose', 'VBP'), ('options', 'NNS'), ('fast', 'VBP'), ('versus', 'JJ'), ('deep', 'JJ'), ('reasoning', 'NN'), (',', ','), ('giving', 'VBG'), ('developers', 'NNS'), ('finer', 'RBR'), ('control', 'VB'), ('latency-versus-accuracy', 'JJ'), ('tradeoffs', 'NNS'), ('.', '.')]\n",
            "[('This', 'DT'), ('make', 'NN'), ('AI', 'NNP'), ('tools', 'VBZ'), ('flexible', 'JJ'), ('better', 'RBR'), ('aligned', 'VBN'), ('practical', 'JJ'), ('workflows', 'NNS'), ('.', '.')]\n",
            "[('Another', 'DT'), ('implication', 'NN'), ('scaling', 'VBG'), ('agents', 'NNS'), ('automation', 'NN'), ('.', '.')]\n",
            "[('As', 'IN'), ('models', 'NNS'), ('get', 'VBP'), ('better', 'RB'), ('orchestrating', 'VBG'), ('tools', 'NNS'), ('managing', 'VBG'), ('memory', 'NN'), (',', ','), ('agentic', 'JJ'), ('workflows', 'NNS'), ('move', 'VBP'), ('demos', 'RB'), ('research', 'NN'), ('prototypes', 'VBZ'), ('production', 'NN'), ('usage', 'NN'), ('across', 'IN'), ('industries', 'NNS'), ('.', '.')]\n",
            "[('Autonomous', 'JJ'), ('assistants', 'NNS'), ('perform', 'VB'), ('multi-step', 'JJ'), ('tasks', 'NNS'), ('increasingly', 'RB'), ('appear', 'VBP'), ('customer', 'NN'), ('support', 'NN'), (',', ','), ('research', 'NN'), ('development', 'NN'), (',', ','), ('software', 'NN'), ('engineering', 'NN'), (',', ','), ('operations', 'NNS'), ('.', '.')]\n",
            "[('AI', 'NNP'), ('become', 'VBP'), ('deeply', 'RB'), ('integrated', 'JJ'), ('business', 'NN'), ('processes', 'NNS'), (',', ','), ('merely', 'RB'), ('used', 'VBD'), ('text', 'JJ'), ('interface', 'NN'), ('.', '.')]\n",
            "[('Safety', 'NNP'), ('also', 'RB'), ('set', 'VBD'), ('become', 'JJ'), ('first-class', 'JJ'), ('engineering', 'NN'), ('priority', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('’', 'NNP'), ('public', 'JJ'), ('work', 'NN'), ('safe-completions', 'NNS'), (',', ','), ('scheming', 'VBG'), ('detection', 'NN'), (',', ','), ('system-level', 'JJ'), ('mitigations', 'NNS'), ('implies', 'NNS'), ('safety', 'NN'), ('engineering', 'NN'), ('tightly', 'RB'), ('integrated', 'VBN'), ('capability', 'NN'), ('gains', 'NNS'), ('.', '.')]\n",
            "[('For', 'IN'), ('adopters', 'NNS'), (',', ','), ('means', 'VBZ'), ('richer', 'JJR'), ('controls', 'NNS'), ('sandboxing', 'VBG'), (',', ','), ('tool-permission', 'JJ'), ('systems', 'NNS'), (',', ','), ('configurable', 'JJ'), ('safety', 'NN'), ('policies', 'NNS'), (',', ','), ('especially', 'RB'), ('enterprise', 'JJ'), ('contexts', 'NN'), ('.', '.')]\n",
            "[('This', 'DT'), ('aligns', 'VBZ'), ('broader', 'JJR'), ('trends', 'NNS'), ('toward', 'IN'), ('responsible', 'JJ'), ('AI', 'NNP'), ('development', 'NN'), (',', ','), ('usability', 'NN'), ('must', 'MD'), ('paired', 'VB'), ('safeguards', 'NNS'), ('.', '.')]\n",
            "[('Commercial', 'JJ'), ('regulatory', 'JJ'), ('pressures', 'NNS'), ('also', 'RB'), ('shape', 'VBP'), ('OpenAI', 'NNP'), ('’', 'NNP'), ('trajectory', 'NN'), ('.', '.')]\n",
            "[('As', 'IN'), ('models', 'NNS'), ('become', 'VBP'), ('powerful', 'JJ'), ('widely', 'RB'), ('adopted', 'VBN'), (',', ','), ('OpenAI', 'NNP'), ('face', 'VBP'), ('increasing', 'VBG'), ('scrutiny', 'NN'), ('regulators', 'NNS'), (',', ','), ('customers', 'NNS'), (',', ','), ('public', 'JJ'), ('around', 'IN'), ('issues', 'NNS'), ('like', 'IN'), ('misuse', 'NN'), (',', ','), ('copyright', 'NN'), (',', ','), ('economic', 'JJ'), ('disruption', 'NN'), ('.', '.')]\n",
            "[('The', 'DT'), ('company', 'NN'), ('need', 'MD'), ('balance', 'VB'), ('opening', 'VBG'), ('capabilities', 'NNS'), ('developers', 'NNS'), ('layered', 'VBD'), ('access', 'NN'), ('controls', 'NNS'), ('transparency', 'NN'), ('measures', 'NNS'), ('maintain', 'VBP'), ('trust', 'NN'), ('.', '.')]\n",
            "[('Its', 'PRP$'), ('future', 'NN'), ('involve', 'VB'), ('technical', 'JJ'), ('innovation', 'NN'), ('also', 'RB'), ('active', 'JJ'), ('engagement', 'JJ'), ('governance', 'NN'), ('policy', 'NN'), ('.', '.')]\n",
            "[('Finally', 'RB'), (',', ','), ('research', 'NN'), ('frontiers', 'NNS'), ('remain', 'VBP'), ('wide', 'JJ'), ('open', 'JJ'), ('.', '.')]\n",
            "[('Despite', 'IN'), ('GPT-5', 'NNP'), ('’', 'NNP'), ('advances', 'NNS'), (',', ','), ('challenges', 'NNS'), ('persist', 'VBP'), (':', ':'), ('fully', 'RB'), ('eliminating', 'VBG'), ('hallucinations', 'NNS'), (',', ','), ('achieving', 'VBG'), ('robust', 'JJ'), ('verifiable', 'JJ'), ('reasoning', 'NN'), (',', ','), ('enabling', 'VBG'), ('compositional', 'JJ'), ('tool', 'NN'), ('use', 'NN'), ('across', 'IN'), ('long', 'JJ'), ('horizons', 'NNS'), (',', ','), ('ensuring', 'VBG'), ('provable', 'JJ'), ('alignment', 'NN'), ('.', '.')]\n",
            "[('OpenAI', 'NNP'), ('’', 'NNP'), ('approach—a', 'VBD'), ('blend', 'NN'), ('scaling', 'NN'), (',', ','), ('architectural', 'JJ'), ('specialization', 'NN'), (',', ','), ('post-training', 'JJ'), ('alignment—offers', 'NNS'), ('one', 'CD'), ('path', 'NN'), ('forward', 'NN'), (',', ','), ('academic', 'JJ'), ('industrial', 'JJ'), ('communities', 'NNS'), ('likely', 'JJ'), ('experiment', 'JJ'), ('alternatives', 'NNS'), ('symbolic', 'JJ'), ('hybrids', 'NNS'), (',', ','), ('neural', 'JJ'), ('theorem', 'NN'), ('proving', 'NN'), (',', ','), ('causal', 'NN'), ('models', 'NNS'), (',', ','), ('new', 'JJ'), ('verification', 'NN'), ('methods', 'NNS'), ('.', '.')]\n",
            "[('The', 'DT'), ('jump', 'NN'), ('GPT-4', 'NNP'), ('GPT-4.5', 'NNP'), ('GPT-5', 'NNP'), ('reads', 'VBZ'), ('less', 'RBR'), ('like', 'IN'), ('single', 'JJ'), ('leap', 'NN'), ('like', 'IN'), ('systems', 'NNS'), ('evolution', 'NN'), ('.', '.')]\n",
            "[('Smarter', 'NNP'), ('routing', 'NN'), (',', ','), ('dedicated', 'VBN'), ('reasoning', 'VBG'), ('brain', 'NN'), (',', ','), ('tighter', 'JJR'), ('tool', 'NN'), ('integration', 'NN'), (',', ','), ('longer', 'JJR'), ('context', 'NN'), ('windows', 'NNS'), (',', ','), ('new', 'JJ'), ('safety-first', 'JJ'), ('training', 'NN'), ('techniques', 'NNS'), ('contribute', 'VBP'), ('making', 'VBG'), ('GPT-5', 'NNP'), ('useful', 'JJ'), ('real', 'JJ'), ('world', 'NN'), ('.', '.')]\n",
            "[('It', 'PRP'), ('faster', 'RBR'), ('everyday', 'JJ'), ('tasks', 'NNS'), (',', ','), ('deeper', 'JJR'), ('complex', 'JJ'), ('problems', 'NNS'), (',', ','), ('safer', 'VBP'), ('many', 'JJ'), ('practical', 'JJ'), ('scenarios', 'NNS'), (',', ','), ('still', 'RB'), ('foregrounding', 'VBG'), ('unresolved', 'JJ'), ('challenges', 'NNS'), ('guide', 'VBP'), ('research', 'NN'), ('policy', 'NN'), ('years', 'NNS'), ('come', 'VBP'), ('.', '.')]\n",
            "[('For', 'IN'), ('developers', 'NNS'), ('organizations', 'NNS'), (',', ','), ('immediate', 'JJ'), ('impact', 'NN'), ('pragmatic', 'JJ'), (':', ':'), ('better', 'JJR'), ('productivity', 'NN'), ('tools', 'NNS'), (',', ','), ('richer', 'RB'), ('agent', 'JJ'), ('capabilities', 'NNS'), (',', ','), ('growing', 'VBG'), ('set', 'NN'), ('controls', 'NNS'), ('safe', 'JJ'), ('deployment', 'NN'), ('.', '.')]\n",
            "[('For', 'IN'), ('broader', 'JJR'), ('field', 'NN'), (',', ','), ('GPT-5', 'JJ'), ('represents', 'VBZ'), ('next', 'JJ'), ('phase', 'NN'), ('making', 'VBG'), ('AI', 'NNP'), ('larger', 'JJR'), (',', ','), ('composable', 'JJ'), (',', ','), ('controllable', 'JJ'), (',', ','), ('context-aware', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Name Entity Recognition\n"
      ],
      "metadata": {
        "id": "cHMH6A3LaEeq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}